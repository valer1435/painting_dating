{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler \n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES_PATH = os.sep.join([\"..\", \"resized_images_augmentated\"]) # относительный путь к папке с картинками\n",
    "\n",
    "CSV_PATH = \"sample_full_augm.csv\"\n",
    "\n",
    "IMAGE_NORMAL_SIZE = (224, 224)\n",
    "GRAM_SIZE = 512\n",
    "\n",
    "RANDOM_SEED = 4545435\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CPU = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, dict_path):\n",
    "        self.transformations = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        self.class_dict = pd.read_csv(dict_path)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        row = self.class_dict.iloc[index]\n",
    "        file_path = row[1]\n",
    "        \n",
    "        data = Image.open(file_path).convert(\"RGB\").resize(IMAGE_NORMAL_SIZE)\n",
    "        data = self.transformations(data)  # (3)\n",
    "        \n",
    "        label = row[2]\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.class_dict.index.shape[0]\n",
    "    \n",
    "\n",
    "class StyleMatrix(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StyleMatrix, self).__init__()\n",
    "\n",
    "    def forward(self, input_):\n",
    "         return __class__.gram_matrix(input_)\n",
    "    \n",
    "    @staticmethod\n",
    "    def gram_matrix(inp): # исправленная версия\n",
    "        a, b, c, d = inp.size()  # a=batch size(=1)\n",
    "        # b=number of feature maps\n",
    "        # (c, d)=dimensions of a f. map (N=c*d)\n",
    "\n",
    "        features = inp.view(a, b, c * d)  # resise F_XL into \\hat F_XL\n",
    "        G = torch.empty((a, b, b))\n",
    "        for i in range(a):\n",
    "            G[i] = torch.mm(features[i], features[i].t())\n",
    "\n",
    "        # we 'normalize' the values of the gram matrix\n",
    "        # by dividing by the number of element in each feature maps.\n",
    "        gram = G.div(a * b * c * d)\n",
    "        left = torch.reshape(gram, (gram.size()[0], gram.size()[1] * gram.size()[2])).to(DEVICE)\n",
    "        right = torch.reshape(inp, (inp.size()[0], inp.size()[1] * inp.size()[2]))\n",
    "        return torch.cat((left, right), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Урезанная сеть ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_18 = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).to(DEVICE)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet34', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet152', pretrained=True)\n",
    "our_resnet_18 = torch.nn.Sequential(*list(resnet_18.children())[:-1]+[StyleMatrix()])\n",
    "torch.save(our_resnet_18.state_dict(), \"our_resnet_18.pth\") # на случай, если придется пересохранять сетку\n",
    "our_resnet_18.load_state_dict(torch.load(\"our_resnet_18.pth\"))\n",
    "our_resnet_18.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание списка всех изображений (номер - путь к файлу - класс) \n",
    "### Аргументы:  \n",
    "**file_path**-название результирующего файла,  \n",
    "**cut_factor**-как \"порезать\" датасет (cut_factor=2 будет выбирать только каждую 2 картинку.  \n",
    "Чем больше cut_factor-тем меньше датасет, выбрать полный датасет-cut_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_classes(file_path, cut_factor=1):\n",
    "    header = \"filename,full_filename,num_class\"\n",
    "    data = header + \"\\n\"\n",
    "    \n",
    "    timeframes = os.listdir(TRAIN_IMAGES_PATH)\n",
    "    \n",
    "    with open(file_path, \"w+\") as file_csv:\n",
    "        for count_class, timeframe in enumerate(timeframes):\n",
    "            timeframe_images_path = TRAIN_IMAGES_PATH+ os.sep + timeframe\n",
    "            images = os.listdir(timeframe_images_path)\n",
    "            img_count = 0\n",
    "            for image_name in images:\n",
    "                img_count+=1\n",
    "                if img_count % cut_factor == 0: \n",
    "                    image_index = image_name.split(\".\")[0]\n",
    "                    image_path = timeframe_images_path + os.sep + image_name\n",
    "                    count_class_this = \"0\" if count_class <= 16 else str(count_class-16)\n",
    "                    data += \"{},{},{}\\n\".format(image_index, image_path, count_class_this)\n",
    "                \n",
    "        file_csv.write(data)\n",
    "CUT_FACTOR = 1\n",
    "generate_csv_classes(CSV_PATH, cut_factor=CUT_FACTOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузчики данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.4\n",
    "TEST_SPLIT = 0.5\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train loader: 11907 (59535 images)\n",
      "Number of batches in validation loader: 7938 (39690 images)\n"
     ]
    }
   ],
   "source": [
    "data = MyCustomDataset(CSV_PATH)\n",
    "\n",
    "dataset_size = len(data) \n",
    "indices = list(range(dataset_size)) \n",
    "\n",
    "split = int(VALIDATION_SPLIT * dataset_size)\n",
    "\n",
    "np.random.seed(RANDOM_SEED) \n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices) \n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(data, batch_size=BATCH_SIZE, num_workers=0, sampler=train_sampler)\n",
    "\n",
    "val_loader = DataLoader(data, batch_size=BATCH_SIZE, num_workers=0, sampler=valid_sampler)\n",
    "\n",
    "print(\"Number of batches in train loader: {} ({} images)\".format(len(train_loader), len(train_loader) * BATCH_SIZE))\n",
    "print(\"Number of batches in validation loader: {} ({} images)\".format(len(val_loader), len(val_loader) * BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков (можно пропустить)\n",
    "Каждую итерацию исключается ровно половина признаков, выявление наиболее важных происходит на 500, 1000, ... объектах в зависимости от текущего количества неисключенных признаков. В конце остаётся ~4000, которые можно сохранить в csv или продолжить работу.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCHES = len(train_loader)\n",
    "MAX_FEATURES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "def select_features(loader, model, mask, n_batches, k):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, (images, labels) in enumerate(loader):\n",
    "        if i > n_batches:\n",
    "            break\n",
    "        actual_batch_size = min(images.shape[0], BATCH_SIZE)\n",
    "        G_matrices = model(torch.reshape(images, (actual_batch_size, 3, *IMAGE_NORMAL_SIZE)).to(DEVICE))\n",
    "        for j in range(actual_batch_size):\n",
    "            X.append(G_matrices[j].cpu().detach().numpy()[mask])\n",
    "        y += labels.tolist()\n",
    "        if ((i + 1) % 500) == 0:\n",
    "            print(i + 1, \"batches out of\", n_batches, \"completed\")\n",
    "    selector = SelectKBest(chi2, k=k)\n",
    "    selector.fit(X, y)\n",
    "    print(\"Selected\", k, \"features from\", len(mask), \"with\", n_batches*BATCH_SIZE, \"objects\")\n",
    "    return mask[list(selector.get_support(indices=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mask_history = []\n",
    "mask = np.array([i for i in range(GRAM_SIZE*GRAM_SIZE)])\n",
    "\n",
    "start_time = time.time()\n",
    "mask = select_features(train_loader, our_resnet_18, mask, N_BATCHES // 6, MAX_FEATURES * 4)\n",
    "print((time.time() - start_time), 'seconds spent\\n')\n",
    "mask = select_features(train_loader, our_resnet_18, mask, N_BATCHES, MAX_FEATURES)\n",
    "print((time.time() - start_time), 'seconds spent\\n')\n",
    "\n",
    "# while len(mask) > MAX_FEATURES:\n",
    "#     start_time = time.time()\n",
    "#     actual_n_batches = N_BATCHES\n",
    "#     mask = select_features(train_loader, our_resnet_18, mask, actual_n_batches, len(mask) // 2)\n",
    "#     mask_history.append(mask)\n",
    "#     print((time.time() - start_time), 'seconds spent\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним номера признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray, save\n",
    "\n",
    "save('features_resnet_kbest_all.npy', asarray(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import asarray, save\n",
    "\n",
    "# save('features_resnet_65000.npy', asarray(mask_history[-4]))\n",
    "# save('features_resnet_32000.npy', asarray(mask_history[-3]))\n",
    "# save('features_resnet_16000.npy', asarray(mask_history[-2]))\n",
    "# save('features_resnet_8000.npy', asarray(mask_history[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пути к файлам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_MASK_PATH = \"features_resnet_kbest_all.npy\" # путь к файлу с маской признаков (в данном случае на 8192 штуки)\n",
    "TRAIN_CSV_PATH = \"train.csv\"\n",
    "VALIDATION_CSV_PATH = \"val.csv\"\n",
    "TEST_CSV_PATH = \"test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перегонка картинок в их признаковое описание\n",
    "Выполнение этого блока необходимо, если у вас нет сконвертированных данных в .csv\n",
    "\n",
    "Если таковые есть, то этот блок стоит пропустить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.load(FEATURES_MASK_PATH)\n",
    "print(\"Number of selected features:\", len(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_dataset(loader, features, model):\n",
    "    X = []\n",
    "    y = []\n",
    "    size = len(loader)\n",
    "    for i, (images, labels) in enumerate(loader):\n",
    "        actual_batch_size = min(images.shape[0], BATCH_SIZE)\n",
    "        G_matrices = model(torch.reshape(images, (actual_batch_size, 3, *IMAGE_NORMAL_SIZE)).to(DEVICE))\n",
    "\n",
    "        for j in range(actual_batch_size):\n",
    "#             X.append(G_matrices[j].cpu().detach().numpy().reshape((1, GRAM_SIZE*GRAM_SIZE))[0][features])\n",
    "            X.append(G_matrices[j].cpu().detach().numpy()[features])\n",
    "        y += labels.tolist()\n",
    "        if ((i + 1) % 1000) == 0:\n",
    "            print(i + 1, \"batches out of\", size, \"completed\")\n",
    "    print(\"Converting results to Pandas DataFrame...\")\n",
    "    df = pd.DataFrame(data=X)\n",
    "    df[\"label\"] = y\n",
    "    print(\"Done.\")\n",
    "    return df\n",
    "\n",
    "df_train = get_features_dataset(train_loader, mask, our_resnet_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = get_features_dataset(val_loader, mask, our_resnet_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(df_val.shape[0] * TEST_SPLIT)\n",
    "df_test, df_val = df_val.iloc[:test_size, :], df_val.iloc[test_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно пропустить, если сохранение не требуется\n",
    "df_train.to_csv(TRAIN_CSV_PATH)\n",
    "print(\"Saved train data\")\n",
    "\n",
    "df_val.to_csv(VALIDATION_CSV_PATH)\n",
    "print(\"Saved validation data\")\n",
    "\n",
    "df_test.to_csv(TEST_CSV_PATH)\n",
    "print(\"Saved test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных из CSV файлов\n",
    "Этот блок необходимо выполнить, если был пропущен предыдущий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train data\n",
      "Loaded validation data\n",
      "Loaded test data\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "print(\"Loaded train data\")\n",
    "\n",
    "df_val = pd.read_csv(VALIDATION_CSV_PATH)\n",
    "print(\"Loaded validation data\")\n",
    "\n",
    "df_test = pd.read_csv(TEST_CSV_PATH)\n",
    "print(\"Loaded test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и тестирование моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import f1_score, mean_squared_error, mean_squared_log_error, confusion_matrix, plot_confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.loc[:, df_train.columns != \"label\"]\n",
    "X_test = df_test.loc[:, df_test.columns != \"label\"]\n",
    "X_val = df_val.loc[:, df_val.columns != \"label\"]\n",
    "\n",
    "y_train = df_train[\"label\"]\n",
    "y_test = df_test[\"label\"]\n",
    "y_val = df_val[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def replace_1300(y): # объединение малочисленных классов (теперь не обязателно (можно будет удалить))\n",
    "#     for i in y.index:\n",
    "#         y[i] = max(y[i], 16)\n",
    "        \n",
    "# replace_1300(y_train)\n",
    "# replace_1300(y_test)\n",
    "# replace_1300(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA (не тестировалось, может долго работать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=6000, svd_solver='randomized')\n",
    "# X_train = pca.fit_transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "# X_val = pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используем SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(n_jobs=-1, verbose=0)\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 59535\n",
      "0.07634164777021919\n",
      "33.29297052154195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-a2a447a94816>:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cmat / np.sum(cmat, axis=0),\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd_predict = sgd.predict(X_val)\n",
    "print(\"Number of train examples:\", len(train_loader) * BATCH_SIZE )\n",
    "print(f1_score(y_val, sgd_predict, average=\"micro\"), mean_squared_error(y_val, sgd_predict), sep=\"\\n\")\n",
    "\n",
    "cmat = confusion_matrix(y_val, sgd_predict)\n",
    "plt.figure(figsize=(7, 7))\n",
    "sns.heatmap(\n",
    "    cmat / np.sum(cmat, axis=0),\n",
    "    annot=False, cbar=False,\n",
    "    xticklabels=[1300 + i*50 for i in range(13)],\n",
    "    yticklabels=[1300 + i*50 for i in range(13)],\n",
    "    cmap=\"Blues\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используем SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "linear_svc = LinearSVC(verbose=2, max_iter=1000)\n",
    "linear_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_predict = linear_svc.predict(X_test)\n",
    "print(\"Number of train examples:\", len(train_loader) * BATCH_SIZE )\n",
    "print(f1_score(y_test, svc_predict, average=\"micro\"), mean_squared_error(y_test, svc_predict), sep=\"\\n\")\n",
    "\n",
    "cmat = confusion_matrix(y_test, svc_predict)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(\n",
    "    cmat / np.sum(cmat, axis=0),\n",
    "    annot=False, cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, mean_squared_error, mean_squared_log_error, confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "NUM_OF_CLASSES = 13\n",
    "print()\n",
    "#[np.where(y_test==16)])\n",
    "squared_error = np.power(y_test-svc_predict, 2)\n",
    "squared_errors_by_classes = []\n",
    "classes = list(range(NUM_OF_CLASSES))\n",
    "for i in range(NUM_OF_CLASSES):\n",
    "    index_mask = np.where(y_test==i)\n",
    "    squared_errors_by_classes.append(\n",
    "        np.power(\n",
    "            np.power(y_test.values[index_mask]-svc_predict[index_mask], 2),\n",
    "            1/2\n",
    "        )\n",
    "    )\n",
    "plt.boxplot(squared_errors_by_classes, labels=classes)\n",
    "plt.show()\n",
    "plt.boxplot(squared_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
